{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'films', using template directory 'C:\\Users\\PC\\anaconda3\\Lib\\site-packages\\scrapy\\templates\\project', created in:\n",
      "    D:\\Inno\\Course3\\DWV\\films\n",
      "\n",
      "You can start your first spider with:\n",
      "    cd films\n",
      "    scrapy genspider example example.com\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import pandas as pd\n",
    "\n",
    "class TableSpider(scrapy.Spider):\n",
    "    name = 'table_spider'\n",
    "    start_urls = ['https://en.wikipedia.org/wiki/List_of_highest-grossing_films']\n",
    "    \n",
    "    def parse(self, response):\n",
    "        h2 = response.xpath('//div[@class=\"mw-heading mw-heading2\"]')[0]\n",
    "        table = h2.xpath('following-sibling::table')[0]\n",
    "        rows = table.xpath('.//tbody/tr')\n",
    "\n",
    "        data=[]\n",
    "        for i in range(len(rows)):\n",
    "            row=rows[i]\n",
    "            data_from_table = row.xpath('.//td | .//th')  # Select all cells (td for data, th for headers)\n",
    "            data_from_table = [cell.xpath('normalize-space(.)').get() for cell in data_from_table]\n",
    "            data.append(data_from_table)\n",
    "    \n",
    "        columns = [\"Rank\", \"Peak\", \"Film Title\", \"Worldwide gross\", \"Release Year\", \"Ref\"]\n",
    "        df = pd.DataFrame(data, columns=columns)\n",
    "        df.to_csv('table.csv', index=False)\n",
    "        self.logger.info(f\"Extracted DataFrame:\\n{df}\")\n",
    "        \n",
    "        # From obtained links, parse into separate df\n",
    "        links = rows.xpath('.//th[@scope=\"row\"]/i/a/@href').getall()\n",
    "        for link in links:\n",
    "            # go to link, parse data\n",
    "            link = response.urljoin('https://en.wikipedia.org'+link)  # Construct full URL\n",
    "            yield scrapy.Request(url=link, callback=self.parse_film_page)\n",
    "            # data.append(box_data)\n",
    "        \n",
    "    def parse_film_page(self, response):\n",
    "        box = response.xpath('//div[@class=\"mw-content-ltr mw-parser-output\"]')[0]\n",
    "        table = box.xpath('.//table[@class=\"infobox vevent\"]')[0]\n",
    "        rows = table.xpath('.//tbody/tr')\n",
    "        \n",
    "        info = {}\n",
    "        target_rows = [\"Directed by\", \"Countries\", \"Box office\", \"Country\"]\n",
    "        for row in rows:\n",
    "            header = row.xpath('.//th[@scope=\"row\"]/text()').get()\n",
    "            if header in target_rows:\n",
    "                value = row.xpath('.//td//text()').get()\n",
    "                # Clean the value: join text, strip whitespace, and remove empty strings\n",
    "                value = ''.join([text.strip() for text in value if text.strip()])\n",
    "                info[header]=value\n",
    "        \n",
    "        df_infobox = pd.DataFrame([info])\n",
    "        # Append to csv\n",
    "        df_infobox.to_csv('box.csv', mode='a', header=False, index=False)\n",
    "        self.logger.info(f\"Extracted infobox data for {response.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 22:49:52 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-02-27 22:49:52 [scrapy.utils.log] INFO: Versions: lxml 5.3.1.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.3.1, Twisted 24.11.0, Python 3.11.11 | packaged by Anaconda, Inc. | (main, Dec 11 2024, 16:34:19) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 25.0.0 (OpenSSL 3.4.1 11 Feb 2025), cryptography 44.0.1, Platform Windows-10-10.0.26100-SP0\n",
      "2025-02-27 22:49:53 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-02-27 22:49:53 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2025-02-27 22:49:53 [scrapy.extensions.telnet] INFO: Telnet Password: 2252fb10835134b3\n",
      "2025-02-27 22:49:53 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-02-27 22:49:53 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'SPIDER_LOADER_WARN_ONLY': True}\n",
      "2025-02-27 22:49:53 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-02-27 22:49:53 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-02-27 22:49:53 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-02-27 22:49:53 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-02-27 22:49:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-02-27 22:49:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/List_of_highest-grossing_films> (referer: None)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted DataFrame:\n",
      "    Rank  Peak  ... Release Year           Ref\n",
      "0   Rank  Peak  ...         Year           Ref\n",
      "1      1     1  ...         2009    [# 1][# 2]\n",
      "2      2     1  ...         2019    [# 3][# 4]\n",
      "3      3     3  ...         2022    [# 5][# 6]\n",
      "4      4     1  ...         1997    [# 7][# 8]\n",
      "5      5     3  ...         2015   [# 9][# 10]\n",
      "6      6     4  ...         2018  [# 11][# 12]\n",
      "7      7     7  ...         2025  [# 13][# 14]\n",
      "8      8     6  ...         2021  [# 15][# 16]\n",
      "9      9     8  ...         2024  [# 17][# 18]\n",
      "10    10     3  ...         2015  [# 19][# 20]\n",
      "11    11     7  ...         2019   [# 21][# 4]\n",
      "12    12     3  ...         2012  [# 22][# 23]\n",
      "13    13     4  ...         2015  [# 24][# 25]\n",
      "14    14    11  ...         2022  [# 26][# 27]\n",
      "15    15    10  ...         2019  [# 28][# 29]\n",
      "16    16    14  ...         2023  [# 30][# 31]\n",
      "17    17     5  ...         2015  [# 32][# 25]\n",
      "18    18    15  ...         2023  [# 33][# 34]\n",
      "19    19     9  ...         2018  [# 35][# 36]\n",
      "20    20     3  ...         2011  [# 37][# 38]\n",
      "21    21    20  ...         2024  [# 39][# 40]\n",
      "22    22     9  ...         2017  [# 41][# 42]\n",
      "23    23    12  ...         2018  [# 43][# 12]\n",
      "24    24     5  ...         2013  [# 44][# 45]\n",
      "25    25    10  ...         2017  [# 46][# 47]\n",
      "26    26    15  ...         2018  [# 48][# 12]\n",
      "27    27    11  ...         2017  [# 49][# 47]\n",
      "28    28     5  ...         2013  [# 50][# 51]\n",
      "29    29    10  ...         2015  [# 52][# 20]\n",
      "30    30    12  ...         2016  [# 53][# 54]\n",
      "31    31    20  ...         2018  [# 55][# 12]\n",
      "32    32     2  ...         2003  [# 56][# 57]\n",
      "33    33  24RK  ...         2019   [# 58][# 4]\n",
      "34    34  23RK  ...         2019  [# 59][# 60]\n",
      "35    35   5RK  ...         2011  [# 61][# 38]\n",
      "36    36     7  ...         2012  [# 62][# 63]\n",
      "37    37    10  ...         2014  [# 64][# 65]\n",
      "38    38     7  ...         2012  [# 66][# 67]\n",
      "39    39    31  ...         2019  [# 68][# 29]\n",
      "40    40    32  ...         2019  [# 69][# 29]\n",
      "41    41    30  ...         2019   [# 70][# 4]\n",
      "42    42  4TS3  ...         2010  [# 71][# 72]\n",
      "43    43     3  ...         2006  [# 73][# 74]\n",
      "44    44    20  ...         2016  [# 75][# 76]\n",
      "45    45    45  ...         2024        [# 77]\n",
      "46    46    34  ...         2019   [# 78][# 4]\n",
      "47    47     2  ...         1999   [# 79][# 8]\n",
      "48    48     6  ...         2011  [# 80][# 72]\n",
      "49    49     1  ...         1993  [# 81][# 82]\n",
      "50    50    24  ...         2017  [# 83][# 47]\n",
      "\n",
      "[51 rows x 6 columns]\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Avatar_(2009_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_Dead_Man%27s_Chest> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Avatar_(2009_film)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Toy_Story_3> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_Dead_Man%27s_Chest\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Despicable_Me_3> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Moana_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_On_Stranger_Tides> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Toy_Story_4> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Rogue_One:_A_Star_Wars_Story> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Aladdin_(2019_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_Episode_I_%E2%80%93_The_Phantom_Menace> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Toy_Story_3\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Despicable_Me_3\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Moana_2\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Jurassic_Park_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Skyfall> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Pirates_of_the_Caribbean:_On_Stranger_Tides\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Toy_Story_4\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_The_Rise_of_Skywalker> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Joker_(2019_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Transformers:_Age_of_Extinction> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Rogue_One:_A_Star_Wars_Story\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Aladdin_(2019_film)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Star_Wars:_Episode_I_%E2%80%93_The_Phantom_Menace\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Transformers:_Dark_of_the_Moon> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Spider-Man:_Far_From_Home> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Captain_Marvel_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Jurassic_Park_(film)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Skyfall\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Aquaman_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Star_Wars:_The_Rise_of_Skywalker\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Joker_(2019_film)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Transformers:_Age_of_Extinction\n",
      "2025-02-27 22:49:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Captain_America:_Civil_War> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:54 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Transformers:_Dark_of_the_Moon\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Spider-Man:_Far_From_Home\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Captain_Marvel_(film)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Minions_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Incredibles_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Aquaman_(film)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Beauty_and_the_Beast_(2017_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Iron_Man_3> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_The_Last_Jedi> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Jurassic_World:_Fallen_Kingdom> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Captain_America:_Civil_War\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Frozen_(2013_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Deadpool_%26_Wolverine> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Incredibles_2\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Minions_(film)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Beauty_and_the_Beast_(2017_film)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Iron_Man_3\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Jurassic_World:_Fallen_Kingdom\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Star_Wars:_The_Last_Jedi\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Frozen_(2013_film)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Deadpool_%26_Wolverine\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/The_Super_Mario_Bros._Movie> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Top_Gun:_Maverick> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Black_Panther_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Furious_7> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Frozen_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Harry_Potter_and_the_Deathly_Hallows_%E2%80%93_Part_2\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Avengers:_Age_of_Ultron> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Barbie_(film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/The_Super_Mario_Bros._Movie\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Jurassic_World> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Ne_Zha_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Top_Gun:_Maverick\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Black_Panther_(film)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Furious_7\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Frozen_2\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Inside_Out_2> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Avengers:_Age_of_Ultron\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Barbie_(film)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Ne_Zha_2\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Jurassic_World\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Spider-Man:_No_Way_Home> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Titanic_(1997_film)> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Avengers:_Infinity_War> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Star_Wars:_The_Force_Awakens> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Inside_Out_2\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Spider-Man:_No_Way_Home\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Titanic_(1997_film)\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Avengers:_Infinity_War\n",
      "2025-02-27 22:49:55 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Star_Wars:_The_Force_Awakens\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Avengers:_Endgame> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://en.wikipedia.org/wiki/Avatar:_The_Way_of_Water> (referer: https://en.wikipedia.org/wiki/List_of_highest-grossing_films)\n",
      "2025-02-27 22:49:56 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Avengers:_Endgame\n",
      "2025-02-27 22:49:56 [table_spider] INFO: Extracted infobox data for https://en.wikipedia.org/wiki/Avatar:_The_Way_of_Water\n",
      "2025-02-27 22:49:56 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-02-27 22:49:56 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 21257,\n",
      " 'downloader/request_count': 46,\n",
      " 'downloader/request_method_count/GET': 46,\n",
      " 'downloader/response_bytes': 5504493,\n",
      " 'downloader/response_count': 46,\n",
      " 'downloader/response_status_count/200': 46,\n",
      " 'elapsed_time_seconds': 2.778538,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 2, 27, 19, 49, 56, 324586, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32465845,\n",
      " 'httpcompression/response_count': 46,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/DEBUG': 47,\n",
      " 'log_count/INFO': 56,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 46,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 46,\n",
      " 'scheduler/dequeued/memory': 46,\n",
      " 'scheduler/enqueued': 46,\n",
      " 'scheduler/enqueued/memory': 46,\n",
      " 'start_time': datetime.datetime(2025, 2, 27, 19, 49, 53, 546048, tzinfo=datetime.timezone.utc)}\n",
      "2025-02-27 22:49:56 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!scrapy runspider spider.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank                            50\n",
      "Film Title         Despicable Me 3\n",
      "Worldwide gross         1034800131\n",
      "Release Year                  2017\n",
      "Directed by          Pierre Coffin\n",
      "Country              United States\n",
      "Name: 40, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import  pandas as pd\n",
    "table=pd.read_csv('table.csv')\n",
    "box=pd.read_csv('box.csv',names=[\"Directed by\", \"Country\", \"Box office\", \"Name\"])\n",
    "\n",
    "# keys for appendings\n",
    "box_key = box.iloc[:, 3]  \n",
    "table_key = table['Film Title']\n",
    "\n",
    "box['key'] = box_key\n",
    "table['key'] = table_key\n",
    "\n",
    "merged_df = pd.merge(table, box, on='key', how='inner')\n",
    "\n",
    "merged_df = merged_df.drop(columns=['key', 'Peak', 'Ref', 'Name', 'Box office'])\n",
    "merged_df['Worldwide gross']=merged_df['Worldwide gross'].apply(lambda x: ''.join( c for c in x if  c not in '$TSMF' )).apply(lambda x: ''.join(x.split(',')))\n",
    "\n",
    "print(merged_df.loc[40])\n",
    "merged_df.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"films_db\"]  \n",
    "collection = db[\"films\"] \n",
    "\n",
    "with open('./data.csv', 'r') as file:\n",
    "    csv_data = csv.DictReader(file)  # Use DictReader to read rows as dictionaries\n",
    "\n",
    "    for row in csv_data:\n",
    "        # Convert numeric fields to integers\n",
    "        row[\"Rank\"] = int(row[\"Rank\"])\n",
    "        row[\"Worldwide gross\"] = int(row[\"Worldwide gross\"])\n",
    "        row[\"Release Year\"] = int(row[\"Release Year\"])\n",
    "\n",
    "        collection.insert_one(row)\n",
    "\n",
    "print(\"Data inserted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson import ObjectId\n",
    "import json\n",
    "\n",
    "# Fetch data from MongoDB collection\n",
    "res = collection.find()\n",
    "\n",
    "# Convert the MongoDB cursor to a list of dictionaries and remove unwanted fields\n",
    "data = []\n",
    "for doc in res:\n",
    "    # Remove the '_id' and empty key ('') fields\n",
    "    doc.pop('_id', None)  # Remove '_id' if it exists\n",
    "    doc.pop('', None)     # Remove empty key if it exists\n",
    "    data.append(doc)\n",
    "\n",
    "# Write the data to a JSON file as a valid JSON array\n",
    "with open('data.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)  # Use json.dump directly with the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dwv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
